{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import dataiku\n",
    "import pandas as pd, numpy as np\n",
    "from dataiku import pandasutils as pdu\n",
    "\n",
    "\n",
    "# Read recipe inputs\n",
    "ghost_trips_booking_pings_cleaned_transformed = dataiku.Dataset(\"ping_data_clean\")\n",
    "ghost_trips_booking_pings_cleaned_transformed_df = ghost_trips_booking_pings_cleaned_transformed.get_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "ghost_trips_booking_pings_cleaned_transformed_df.label.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math as m"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def transform_raw_df(df):\n",
    "    \"\"\"Clean and engineer features for raw df\n",
    "\n",
    "    IMPORTANT.\n",
    "    - This function assumes that the row is ordered by epochs for every driver.\n",
    "    - If number of pings less than threshold, will return empty df.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): raw df\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: clean and filtered df with new features.\n",
    "    \"\"\"\n",
    "    df = drop_null_location(df)\n",
    "#     df = PingsCleaner.clean_pings_by_driver_status(df)\n",
    "#     df = self.filter_orders(df, self.trip_threshold)\n",
    "    if df.empty:\n",
    "        return df\n",
    "    df = df.sort_values([\"order_no\", \"seconds\"])\n",
    "    df = DistanceFeatures.create_features(df)\n",
    "    df = CoordsFeatures.create_features(df)\n",
    "    return df\n",
    "\n",
    "\n",
    "def drop_null_location(df):\n",
    "    \"\"\"remove row with unknown location\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): raw df to be cleaned\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: cleaned df\n",
    "    \"\"\"\n",
    "\n",
    "    df = df.dropna(subset=[\"latitude\", \"longitude\"])\n",
    "    return df\n",
    "\n",
    "\n",
    "# def filter_orders(df, trip_threshold):\n",
    "#     \"\"\"Filter drivers whose number of pings are below certain threshold\n",
    "\n",
    "#     Args:\n",
    "#         df (pd.DataFrame): cleaned df\n",
    "\n",
    "#     Returns:\n",
    "#         pd.DataFrame: filtered df\n",
    "#     \"\"\"\n",
    "#     trip_counts = df[\"order_no\"].value_counts(dropna=False)\n",
    "#     val_ids = trip_counts[trip_counts > trip_threshold].index.values\n",
    "#     df = df.loc[df[\"order_no\"].isin(val_ids), :]\n",
    "#     return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class DistanceFeatures:\n",
    "def create_ping_features(df):\n",
    "    \"\"\"Engineer features using distance between pings\n",
    "\n",
    "    List of additional features:\n",
    "    - `distance`\n",
    "    - `calculated_speed`\n",
    "    - `time_diff`\n",
    "\n",
    "    The feature that is used in the `aggregated_features` is `calculated_speed`.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): filtered df\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: df with additional features `distance`, `time_diff`, `calculated_speed`\n",
    "    \"\"\"\n",
    "\n",
    "    df[\"latlong\"] = list(zip(df[\"latitude\"], df[\"longitude\"]))\n",
    "    df[\"distance\"] = df.groupby(\"order_no\")[\"latlong\"].transform(\n",
    "        calc_distance_between_pings\n",
    "    )\n",
    "    df[\"time_diff\"] = df.groupby(\"order_no\")[\"seconds\"].diff()\n",
    "    df[\"calculated_speed\"] = df[\"distance\"] / df[\"time_diff\"]\n",
    "    df[\"calculated_speed\"] = df[\"calculated_speed\"].replace(\n",
    "        [np.inf, -np.inf], np.nan\n",
    "    )\n",
    "    df = df.drop(\"latlong\", axis=1)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def calc_distance_between_pings(coords):\n",
    "    \"\"\"Calculate distance between pings\n",
    "\n",
    "    Important.\n",
    "    - The ping sequence has to be originated from the same driver.\n",
    "\n",
    "    Args:\n",
    "        coords (array-like): list of tuples of latitude longitude\n",
    "\n",
    "    Returns:\n",
    "        list: distance between pings\n",
    "    \"\"\"\n",
    "\n",
    "    if isinstance(coords, pd.DataFrame) or isinstance(coords, pd.Series):\n",
    "        coords = coords.values\n",
    "    temp = [0]\n",
    "    for i in range(1, len(coords)):\n",
    "        temp.append(calculate_dist(coords[i], coords[i - 1]))\n",
    "    return temp\n",
    "\n",
    "\n",
    "def calculate_dist(loc_next, loc_current, R=6373.0):\n",
    "    \"\"\"Calculate distance between two coordinates\n",
    "\n",
    "    Args:\n",
    "        loc_next (tuple): latitude longitude\n",
    "        loc_current (tuple): latitude longitude\n",
    "        R (float, optional): Defaults to 6373.0. earth's radius\n",
    "\n",
    "    Returns:\n",
    "        float: distance between `loc_next` and `loc_current`\n",
    "    \"\"\"\n",
    "\n",
    "    lat1, lon1 = loc_current\n",
    "    lat2, lon2 = loc_next\n",
    "    lat1, lon1, lat2, lon2 = map(m.radians, [lat1, lon1, lat2, lon2])\n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "    a = m.sin(dlat / 2) ** 2 + m.cos(lat1) * m.cos(lat2) * m.sin(dlon / 2) ** 2\n",
    "    c = 2 * m.atan2(m.sqrt(a), m.sqrt(1 - a))\n",
    "    distance = R * c * 1000\n",
    "    return distance\n",
    "\n",
    "\n",
    "# class CoordsFeatures:\n",
    "\n",
    "def create_coord_features(df):\n",
    "    \"\"\"Engineer features based on latitude longitude\n",
    "\n",
    "    List of additional features:\n",
    "    - `lat_change`\n",
    "    - `long_change`\n",
    "    - `weak_dir_change`\n",
    "    - `strong_dir_change`\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): filtered df\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: df with additional features\n",
    "    \"\"\"\n",
    "\n",
    "    df = create_position_changes(df)\n",
    "    df = create_dir_changes(df)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def create_position_changes(df):\n",
    "    df[\"lat_change\"] = df.groupby(\"order_no\")[\"latitude\"].transform(\n",
    "        position_change\n",
    "    )\n",
    "    df[\"long_change\"] = df.groupby(\"order_no\")[\"longitude\"].transform(\n",
    "        position_change\n",
    "    )\n",
    "    return df\n",
    "\n",
    "\n",
    "def position_change(coord):\n",
    "    \"\"\"latitude or longitude change\n",
    "\n",
    "    Pseudocode:\n",
    "\n",
    "        if the coord is the same, assign 0\n",
    "        else if the current coord is greater than the previous coord, assign -1\n",
    "        else assign 1\n",
    "\n",
    "    Args:\n",
    "        coord (array-like): list of latitudes or longitudes\n",
    "\n",
    "    Returns:\n",
    "        list: coord changes\n",
    "    \"\"\"\n",
    "\n",
    "    if isinstance(coord, pd.DataFrame) or isinstance(coord, pd.Series):\n",
    "        coord = coord.values\n",
    "    temp = [0]\n",
    "    for i in range(1, len(coord)):\n",
    "        if np.isnan(coord[i]) or np.isnan(coord[i - 1]):\n",
    "            temp.append(np.nan)\n",
    "            continue\n",
    "        if coord[i] == coord[i - 1]:\n",
    "            temp.append(0)\n",
    "        elif coord[i] > coord[i - 1]:\n",
    "            temp.append(-1)\n",
    "        else:\n",
    "            temp.append(1)\n",
    "    return temp\n",
    "\n",
    "\n",
    "def create_dir_changes(df):\n",
    "    df[\"lat_long_change\"] = list(zip(df[\"lat_change\"], df[\"long_change\"]))\n",
    "    df[\"weak_dir_change\"] = df.groupby(\"order_no\")[\"lat_long_change\"].transform(\n",
    "        lambda x: dir_change(x, \"weak\")\n",
    "    )\n",
    "    df[\"strong_dir_change\"] = df.groupby(\"order_no\")[\"lat_long_change\"].transform(\n",
    "        lambda x: dir_change(x, \"strong\")\n",
    "    )\n",
    "    df = df.drop([\"lat_long_change\"], axis=1)\n",
    "    return df\n",
    "\n",
    "\n",
    "def dir_change(coords_changes, change=\"weak\"):\n",
    "    \"\"\"Direction Change\n",
    "\n",
    "    Calculate change of latitude or longitude of the pings\n",
    "\n",
    "    Weak direction change:\n",
    "\n",
    "        if lat_change or long_change changes, then 1\n",
    "        else 0\n",
    "\n",
    "    Strong direction change:\n",
    "\n",
    "        if lat_change and long_change change, then 1\n",
    "        else 0\n",
    "\n",
    "    Args:\n",
    "        coords_changes ([type]): list of latitude longitude changes tuples.\n",
    "        change (str, optional): Defaults to 'weak'. [description]\n",
    "\n",
    "    Returns:\n",
    "        list: list of direction changes indicator\n",
    "    \"\"\"\n",
    "\n",
    "    if isinstance(coords_changes, pd.DataFrame) or isinstance(\n",
    "        coords_changes, pd.Series\n",
    "    ):\n",
    "        coords_changes = coords_changes.values\n",
    "    temp = [0]\n",
    "    for i in range(1, len(coords_changes)):\n",
    "\n",
    "        if coords_changes_isnull(\n",
    "            coords_changes[i]\n",
    "        ) or coords_changes_isnull(coords_changes[i - 1]):\n",
    "            temp.append(np.nan)\n",
    "            continue\n",
    "\n",
    "        lat_change1, long_change1 = coords_changes[i]\n",
    "        lat_change2, long_change2 = coords_changes[i - 1]\n",
    "\n",
    "        if change == \"weak\":\n",
    "            # Weak direction change\n",
    "            temp.append(\n",
    "                1\n",
    "                if not (lat_change1 == lat_change2)\n",
    "                or not (long_change1 == long_change2)\n",
    "                else 0\n",
    "            )\n",
    "        else:\n",
    "            # Strong direction change\n",
    "            temp.append(\n",
    "                0\n",
    "                if (lat_change1 == lat_change2) or (long_change1 == long_change2)\n",
    "                else 1\n",
    "            )\n",
    "\n",
    "    return temp\n",
    "\n",
    "\n",
    "def coords_changes_isnull(coords_changes):\n",
    "    lat_change, long_change = coords_changes\n",
    "    return np.isnan(lat_change) or np.isnan(long_change)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "ping_features = create_ping_features(ghost_trips_booking_pings_cleaned_transformed_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "ping_features.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "coord_features = create_coord_features(ghost_trips_booking_pings_cleaned_transformed_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "coord_features.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assemble(disaggregated_df, key, mode=\"train\"):\n",
    "    \"\"\"Aggregate features with respect to `key`\n",
    "\n",
    "    If mode == `test`, do not append `label` column to the `aggregated_df`.\n",
    "\n",
    "    Args:\n",
    "        disaggregated_df (pd.DataFrame): df to aggregate\n",
    "        key (str): key pivot to aggregate the features\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: aggregated df\n",
    "    \"\"\"\n",
    "\n",
    "    disaggregated_df = disaggregated_df.sort_values(\n",
    "        [\"order_no\", \"seconds\"]\n",
    "    ).reset_index(drop=True)\n",
    "\n",
    "    aggregated_dfs = []\n",
    "    if key == \"order_no\":\n",
    "        # Index is `order_no`\n",
    "\n",
    "        aggregated_dfs += [assemble_TripLevelFeatures(disaggregated_df)]\n",
    "\n",
    "        aggregated_dfs += [assemble_TripLevelDriverStatusFeatures(disaggregated_df)]\n",
    "\n",
    "    aggregated_df = join_df_on_index(aggregated_dfs)\n",
    "\n",
    "    # NOTE: Need to beware of the index\n",
    "    aggregated_df = aggregated_df[aggregated_features(key)]\n",
    "\n",
    "    if mode == \"train\" and key == \"order_no\":\n",
    "        booking_labels = (\n",
    "            disaggregated_df[[\"order_no\", \"label\"]]\n",
    "            .drop_duplicates()\n",
    "            .set_index(\"order_no\")\n",
    "        )\n",
    "        aggregated_df = aggregated_df.merge(\n",
    "            booking_labels, left_index=True, right_index=True\n",
    "        ).reset_index()\n",
    "\n",
    "    return aggregated_df\n",
    "\n",
    "\n",
    "def join_df_on_index(aggregated_dfs):\n",
    "    \"\"\"Join difference `aggregated_df` on index\n",
    "\n",
    "    Args:\n",
    "        aggregated_dfs (list): list of pd.DataFrame `aggregated_df`\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: joined df\n",
    "    \"\"\"\n",
    "    aggregated_df = reduce(\n",
    "        lambda left, right: pd.merge(\n",
    "            left, right, left_index=True, right_index=True\n",
    "        ),\n",
    "        aggregated_dfs,\n",
    "    )\n",
    "    return aggregated_df\n",
    "\n",
    "\n",
    "def concatenate_dfs(dfs, columns_if_empty):\n",
    "    if len(dfs) == 0:\n",
    "        return pd.DataFrame([], columns=columns_if_empty)\n",
    "    return pd.concat(dfs, axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assemble_TripLevelFeatures(disaggregated_df, suffix=None):\n",
    "\n",
    "        aggregated_dfs = [\n",
    "            trip_statistics(disaggregated_df, \"calculated_speed\"),\n",
    "            trip_statistics(disaggregated_df, \"altitude_in_meters\"),\n",
    "            trip_statistics(disaggregated_df, \"accuracy_in_meters\"),\n",
    "            #trip_statistics(disaggregated_df, \"measured_speed\"),\n",
    "            trip_statistics(disaggregated_df, \"weak_dir_change\", [\"mean\"]),\n",
    "            trip_statistics(disaggregated_df, \"strong_dir_change\", [\"mean\"]),\n",
    "            trip_statistics(disaggregated_df, \"distance\", [\"sum\"]),\n",
    "            trip_statistics(disaggregated_df, \"latitude\", [\"mean\"]),\n",
    "            trip_statistics(disaggregated_df, \"longitude\", [\"mean\"]),\n",
    "            trip_statistics(disaggregated_df, \"time_diff\"),\n",
    "            trip_statistics(disaggregated_df, \"lat_change\", [\"std\"]),\n",
    "            trip_dir_change_perc(\n",
    "                disaggregated_df, [\"lat_change\", \"long_change\"], \"up\"\n",
    "            ),\n",
    "            trip_dir_change_perc(\n",
    "                disaggregated_df, [\"lat_change\", \"long_change\"], \"down\"\n",
    "            ),\n",
    "            trip_duration(disaggregated_df),\n",
    "            trip_pings_count(disaggregated_df),\n",
    "            trip_pings_overlapping_count(disaggregated_df),\n",
    "            time_on_point_accept(disaggregated_df),\n",
    "        ]\n",
    "\n",
    "        aggregated_df = pd.concat(aggregated_dfs, axis=1)\n",
    "        aggregated_df = generate_interaction_features(aggregated_df)\n",
    "\n",
    "        return aggregated_df\n",
    "\n",
    "\n",
    "def trip_statistics(\n",
    "    disaggregated_df, column, stats=[\"mean\", \"median\", \"max\", \"min\", \"std\"]\n",
    "):\n",
    "\n",
    "    # calculate statistics of trip\n",
    "    names = {stat: \"ping_sequence_{}_{}\".format(column, stat) for stat in stats}\n",
    "\n",
    "    if disaggregated_df[column].isnull().all():\n",
    "        # If the whole column is Null, set every statistics to null\n",
    "        df = pd.DataFrame(\n",
    "            None,\n",
    "            columns=names.values(),\n",
    "            index=pd.Index(disaggregated_df[\"order_no\"].unique(), name=\"order_no\"),\n",
    "        )\n",
    "        return df\n",
    "\n",
    "    df = (\n",
    "        disaggregated_df.groupby(\"order_no\")[column]\n",
    "        .agg(stats)\n",
    "        .rename(columns = names)\n",
    "    )\n",
    "    return df\n",
    "\n",
    "\n",
    "def trip_dir_change_perc(disaggregated_df, columns, mode=\"up\"):\n",
    "\n",
    "    val = 1 if mode == \"up\" else -1\n",
    "    names = {\n",
    "        column: \"ping_sequence_{}_{}_perc\".format(column, mode)\n",
    "        for column in columns\n",
    "    }\n",
    "    df = (\n",
    "        disaggregated_df.groupby(\"order_no\")[columns]\n",
    "        .apply(lambda x: np.sum(x == val) / len(x))\n",
    "        .rename(columns = names)\n",
    "    )\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def trip_duration(disaggregated_df):\n",
    "\n",
    "    df = disaggregated_df.groupby(\"order_no\")[\"seconds\"].apply(\n",
    "        lambda x: np.nanmax(x) - np.nanmin(x)\n",
    "    )\n",
    "    df.name = \"ping_sequence_total_duration\"\n",
    "    return df\n",
    "\n",
    "\n",
    "def trip_pings_count(disaggregated_df):\n",
    "    df = disaggregated_df.groupby(\"order_no\").size()\n",
    "    df.name = \"ping_sequence_count\"\n",
    "    return df\n",
    "\n",
    "\n",
    "def generate_interaction_features(aggregated_df):\n",
    "\n",
    "    aggregated_df[\"ping_sequence_avg_speed\"] = (\n",
    "        aggregated_df[\"ping_sequence_distance_sum\"]\n",
    "        / aggregated_df[\"ping_sequence_total_duration\"]\n",
    "    )\n",
    "    return aggregated_df\n",
    "\n",
    "\n",
    "def time_on_point_accept(disaggregated_df):\n",
    "    # TODO: Add unit tests\n",
    "    df = disaggregated_df.groupby(\"order_no\").apply(_time_on_point_accept)\n",
    "    df.name = \"seconds_on_same_latlong_as_ping_bef_accept\"\n",
    "    return df\n",
    "\n",
    "\n",
    "def _time_on_point_accept(pings):\n",
    "    # TODO: Add unit test\n",
    "\n",
    "    available_pings = pings[pings.driver_status == \"AVAILABLE\"]\n",
    "    if available_pings.empty:\n",
    "        return np.nan\n",
    "\n",
    "    available_ping = available_pings.iloc[-1]\n",
    "    lat_accept = available_ping[\"latitude\"]\n",
    "    long_accept = available_ping[\"longitude\"]\n",
    "    seconds_accept = available_ping[\"seconds\"]\n",
    "\n",
    "    suspicious_pings = pings[\n",
    "        (pings[\"latitude\"] == lat_accept)\n",
    "        & (pings[\"longitude\"] == long_accept)\n",
    "        & (pings[\"driver_status\"].isin([\"OTW_PICKUP\", \"OTW_DROPOFF\"]))\n",
    "    ]\n",
    "\n",
    "    if suspicious_pings.empty:\n",
    "        return 0\n",
    "    return suspicious_pings[\"seconds\"].iloc[-1] - seconds_accept\n",
    "\n",
    "\n",
    "def trip_dir_change_mean(aggregated_df):\n",
    "    # TODO: Add unit tests\n",
    "    aggregated_df[\"ping_sequence_dir_change_mean\"] = aggregated_df.apply(\n",
    "        _trip_dir_change_mean, axis=1\n",
    "    )\n",
    "    return aggregated_df\n",
    "\n",
    "\n",
    "def _trip_dir_change_mean(row):\n",
    "    # TODO: Add unit tests\n",
    "    Xw = row[\"ping_sequence_weak_dir_change_mean\"]\n",
    "    Xs = row[\"ping_sequence_strong_dir_change_mean\"]\n",
    "    if Xs >= 0.86:\n",
    "        return 0\n",
    "    elif Xs > 0.6 and Xs <= 0.8:\n",
    "        w = 0.6\n",
    "    else:\n",
    "        w = 1.25\n",
    "    return (w * Xw) + (1 - w) * Xs\n",
    "\n",
    "\n",
    "def trip_pings_overlapping_count(disaggregated_df):\n",
    "    # TODO: Add unit tests\n",
    "    # disaggregated_df[\"rank_ping_dist\"] = (\n",
    "    #     disaggregated_df.groupby(\"order_no\")[\"distance\"].transform(\n",
    "    #         lambda x: (x != x.shift()).cumsum()\n",
    "    #     )\n",
    "    #     - 1\n",
    "    # )\n",
    "    # df = disaggregated_df.groupby(\"order_no\")[\"rank_ping_dist\"].apply(\n",
    "    #     lambda x: (x.value_counts() >= 15).sum()\n",
    "    # )\n",
    "\n",
    "    df = disaggregated_df.groupby(\"order_no\")[\"distance\"].apply(\n",
    "        _trip_pings_overlapping_count\n",
    "    )\n",
    "    df.name = \"ping_sequence_overlapping_count\"\n",
    "    return df\n",
    "\n",
    "\n",
    "def _trip_pings_overlapping_count(distance):\n",
    "    # TODO: Add unit tests\n",
    "    rank_ping_dist = (distance != distance.shift()).cumsum()\n",
    "    return (rank_ping_dist.value_counts() >= 15).sum()\n",
    "\n",
    "# @staticmethod\n",
    "# def _trip_pings_overlapping_count(group):\n",
    "#     # TODO: Add unit tests\n",
    "#     group[\"rank_ping_dist\"] = (\n",
    "#         group[\"distance\"] != group[\"distance\"].shift()\n",
    "#     ).cumsum()\n",
    "#     rank_dist = group[\"rank_ping_dist\"].unique()\n",
    "#     overlapping_count = 0\n",
    "#     for y in rank_dist:\n",
    "#         if group[group[\"rank_ping_dist\"] == y].shape[0] >= 15:\n",
    "#             overlapping_count += 1\n",
    "#     return overlapping_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assemble_TripLevelDriverStatusFeatures(disaggregated_df):\n",
    "    pings_before_accept, pings_during_pickup = separate_pings_by_driver_status(\n",
    "        disaggregated_df\n",
    "    )\n",
    "\n",
    "    aggregated_dfs = [\n",
    "        assemble_for_group(pings_before_accept, group=\"before_accept\"),\n",
    "        assemble_for_group(pings_during_pickup, group=\"during_pickup\"),\n",
    "    ]\n",
    "\n",
    "    aggregated_df = join_df_on_index(aggregated_dfs)\n",
    "    return aggregated_df\n",
    "\n",
    "\n",
    "def assemble_for_group(disaggregated_df, group):\n",
    "\n",
    "    if group == \"before_accept\":\n",
    "\n",
    "        aggregated_dfs = [\n",
    "            trip_statistics(\n",
    "                disaggregated_df, \"accuracy_in_meters\", [\"min\", \"mean\"]\n",
    "            ),\n",
    "            trip_statistics(\n",
    "                disaggregated_df, \"weak_dir_change\", [\"mean\"]\n",
    "            ),\n",
    "            trip_statistics(\n",
    "                disaggregated_df, \"strong_dir_change\", [\"mean\"]\n",
    "            ),\n",
    "            trip_dir_change_perc(\n",
    "                disaggregated_df, [\"lat_change\", \"long_change\"], \"up\"\n",
    "            ),\n",
    "            trip_dir_change_perc(\n",
    "                disaggregated_df, [\"lat_change\", \"long_change\"], \"down\"\n",
    "            ),\n",
    "        ]\n",
    "\n",
    "    elif group == \"during_pickup\":\n",
    "\n",
    "        aggregated_dfs = [\n",
    "            trip_statistics(\n",
    "                disaggregated_df, \"accuracy_in_meters\", [\"min\"]\n",
    "            ),\n",
    "            trip_statistics(\n",
    "                disaggregated_df, \"weak_dir_change\", [\"mean\"]\n",
    "            ),\n",
    "            trip_statistics(\n",
    "                disaggregated_df, \"strong_dir_change\", [\"mean\"]\n",
    "            ),\n",
    "            trip_dir_change_perc(\n",
    "                disaggregated_df, [\"lat_change\", \"long_change\"], \"up\"\n",
    "            ),\n",
    "            trip_dir_change_perc(\n",
    "                disaggregated_df, [\"lat_change\", \"long_change\"], \"down\"\n",
    "            ),\n",
    "        ]\n",
    "\n",
    "    else:\n",
    "        raise ValueError\n",
    "\n",
    "    aggregated_df = pd.concat(aggregated_dfs, axis=1)\n",
    "\n",
    "    if group == \"before_accept\":\n",
    "        aggregated_df = trip_dir_change_mean(aggregated_df)\n",
    "\n",
    "    suffix = \"_\" + group\n",
    "    columns = list(aggregated_df.columns)\n",
    "    aggregated_df = aggregated_df.rename(\n",
    "        columns={col: col + suffix for col in columns}\n",
    "    )\n",
    "\n",
    "    return aggregated_df\n",
    "\n",
    "\n",
    "def separate_pings_by_driver_status(disaggregated_df):\n",
    "    \"\"\"Group pings into different subsets based on `driver_status`\n",
    "\n",
    "    NOTE: Assume that for every order, the pings would come in the order\n",
    "\n",
    "        AVAILABLE/UNAVAILABLE -> OTW_PICKUP -> OTW_DROPOFF\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    driver_status = disaggregated_df.driver_status\n",
    "\n",
    "    pings_before_accept = disaggregated_df[\n",
    "        driver_status.isin([\"AVAILABLE\", \"UNAVAILABLE\"])\n",
    "    ].reset_index(drop=True)\n",
    "\n",
    "    pings_during_pickup = disaggregated_df[\n",
    "        driver_status.isin([\"OTW_PICKUP\"])\n",
    "    ].reset_index(drop=True)\n",
    "\n",
    "    return pings_before_accept, pings_during_pickup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregated_features(key=None):\n",
    "    if key is None:\n",
    "        return aggregated_features(\"order_no\")\n",
    "    if key == \"order_no\":\n",
    "        return [\n",
    "            #####################\n",
    "            ###### Overall ######\n",
    "            #####################\n",
    "            # \"ping_sequence_calculated_speed_mean\",\n",
    "            # \"ping_sequence_calculated_speed_median\",\n",
    "            # \"ping_sequence_calculated_speed_max\",\n",
    "            # \"ping_sequence_calculated_speed_min\",\n",
    "            # \"ping_sequence_calculated_speed_std\",\n",
    "            # \"ping_sequence_altitude_mean\",\n",
    "            # \"ping_sequence_altitude_median\",\n",
    "            # \"ping_sequence_altitude_max\",\n",
    "            # \"ping_sequence_altitude_min\",\n",
    "            # \"ping_sequence_altitude_std\",\n",
    "            # \"ping_sequence_accuracy_mean\",\n",
    "            # \"ping_sequence_accuracy_median\",\n",
    "            # \"ping_sequence_accuracy_max\",\n",
    "            # \"ping_sequence_accuracy_min\",\n",
    "            # \"ping_sequence_accuracy_std\",\n",
    "            # 'ping_sequence_measured_speed_mean',\n",
    "            # 'ping_sequence_measured_speed_median',\n",
    "            # 'ping_sequence_measured_speed_max',\n",
    "            # 'ping_sequence_measured_speed_min',\n",
    "            # 'ping_sequence_measured_speed_std',\n",
    "            # \"ping_sequence_weak_dir_change_mean\",\n",
    "            # \"ping_sequence_strong_dir_change_mean\",\n",
    "            \"ping_sequence_lat_change_std\",\n",
    "            # \"ping_sequence_lat_change_down_perc\",\n",
    "            # \"ping_sequence_lat_change_up_perc\",\n",
    "            # \"ping_sequence_long_change_down_perc\",\n",
    "            # \"ping_sequence_long_change_up_perc\",\n",
    "            # \"ping_sequence_avg_speed\",\n",
    "            \"seconds_on_same_latlong_as_ping_bef_accept\",\n",
    "            \"ping_sequence_overlapping_count\",\n",
    "            #####################\n",
    "            ### Before Accept ###\n",
    "            #####################\n",
    "            \"ping_sequence_accuracy_in_meters_min_before_accept\",\n",
    "            \"ping_sequence_accuracy_in_meters_mean_before_accept\",\n",
    "            \"ping_sequence_weak_dir_change_mean_before_accept\",\n",
    "            \"ping_sequence_strong_dir_change_mean_before_accept\",\n",
    "            #####################\n",
    "            ### During Pickup ###\n",
    "            #####################\n",
    "            \"ping_sequence_accuracy_in_meters_min_during_pickup\",\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_level_features = assemble(coord_features, 'order_no', mode=\"train\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "test[test['order_no']=='RB-2351918226'].label.unique()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "trip_level_features.isnull().sum()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "trip_level_features"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "test[test['order_no']=='RB-2278242197'][['driver_status', 'latitude', 'longitude', 'seconds']]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "18548-18514"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "test.order_no.nunique()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def _time_on_point_accept(pings):\n",
    "    # TODO: Add unit test\n",
    "\n",
    "    available_pings = pings[pings.driver_status == \"AVAILABLE\"]\n",
    "    if available_pings.empty:\n",
    "        return np.nan\n",
    "\n",
    "    available_ping = available_pings.iloc[-1]\n",
    "    lat_accept = available_ping[\"latitude\"]\n",
    "    long_accept = available_ping[\"longitude\"]\n",
    "    seconds_accept = available_ping[\"seconds\"]\n",
    "\n",
    "    suspicious_pings = pings[\n",
    "        (pings[\"latitude\"] == lat_accept)\n",
    "        & (pings[\"longitude\"] == long_accept)\n",
    "        & (pings[\"driver_status\"].isin([\"OTW_PICKUP\", \"OTW_DROPOFF\"]))\n",
    "    ]\n",
    "\n",
    "    if suspicious_pings.empty:\n",
    "        return 0\n",
    "    return suspicious_pings[\"seconds\"].iloc[-1] - seconds_accept"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "### Unit test for time_on_point_accept"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def test_time_on_point_accept():\n",
    "\n",
    "        list_of_lists = []\n",
    "        list_of_lists.append([1,'AVAILABLE', 1,1,1])\n",
    "        list_of_lists.append([1,'AVAILABLE', 1,1,2])\n",
    "        list_of_lists.append([1,'AVAILABLE', 1,1,3])\n",
    "        list_of_lists.append([1,'AVAILABLE', 1,1,4])\n",
    "        list_of_lists.append([1,'OTW_PICKUP', 1,1,5])\n",
    "        list_of_lists.append([1,'OTW_PICKUP', 1,1,6])\n",
    "        list_of_lists.append([1,'OTW_PICKUP', 1,1,7])\n",
    "        list_of_lists.append([1,'OTW_PICKUP', 1,1,8])\n",
    "        list_of_lists.append([1,'OTW_DROPOFF', 1,2,8])\n",
    "        list_of_lists.append([2,'AVAILABLE', 1,1,1])\n",
    "        list_of_lists.append([2,'AVAILABLE', 1,1,2])\n",
    "        list_of_lists.append([2,'AVAILABLE', 1,1,3])\n",
    "        list_of_lists.append([2,'AVAILABLE', 1,1,4])\n",
    "        list_of_lists.append([2,'OTW_PICKUP', 1,1,5])\n",
    "        list_of_lists.append([2,'OTW_PICKUP', 1,2,6])\n",
    "        list_of_lists.append([2,'OTW_PICKUP', 1,2,7])\n",
    "        list_of_lists.append([1,'OTW_DROPOFF', 1,2,8])\n",
    "\n",
    "\n",
    "\n",
    "        test_df = pd.DataFrame(list_of_lists, columns=[\"order_no\",\"driver_status\", \"latitude\", \"longitude\", \"seconds\"])\n",
    "        test_series = pd.Series(time_on_point_accept(test_df), name=\"seconds_on_same_latlong_as_ping_bef_accept\", index=pd.Index([1,2]))\n",
    "\n",
    "\n",
    "        list_of_values = []\n",
    "        list_of_values.append(4)\n",
    "        list_of_values.append(1)\n",
    "\n",
    "        expected_series = pd.Series(\n",
    "            list_of_values,\n",
    "            name=\"seconds_on_same_latlong_as_ping_bef_accept\",\n",
    "            index=pd.Index([1,2])\n",
    "        )\n",
    "\n",
    "\n",
    "        pd.testing.assert_series_equal(expected_series, test_series)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "test_time_on_point_accept()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "### Unit test for pings overlap count"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def trip_pings_overlapping_count(disaggregated_df):\n",
    "    # TODO: Add unit tests\n",
    "    # disaggregated_df[\"rank_ping_dist\"] = (\n",
    "    #     disaggregated_df.groupby(\"order_no\")[\"distance\"].transform(\n",
    "    #         lambda x: (x != x.shift()).cumsum()\n",
    "    #     )\n",
    "    #     - 1\n",
    "    # )\n",
    "    # df = disaggregated_df.groupby(\"order_no\")[\"rank_ping_dist\"].apply(\n",
    "    #     lambda x: (x.value_counts() >= 15).sum()\n",
    "    # )\n",
    "\n",
    "    df = disaggregated_df.groupby(\"order_no\")[\"distance\"].apply(\n",
    "        _trip_pings_overlapping_count\n",
    "    )\n",
    "    df.name = \"ping_sequence_overlapping_count\"\n",
    "    return df\n",
    "\n",
    "\n",
    "def _trip_pings_overlapping_count(distance):\n",
    "    # TODO: Add unit tests\n",
    "    rank_ping_dist = (distance != distance.shift()).cumsum()\n",
    "    return (rank_ping_dist.value_counts() >= 15).sum()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def test_pings_overlapping_count():\n",
    "\n",
    "        list_of_lists = []\n",
    "        list_of_lists.append([1,1])\n",
    "        list_of_lists.append([1,1])\n",
    "        list_of_lists.append([1,1])\n",
    "        list_of_lists.append([1,1])\n",
    "        list_of_lists.append([1,1])\n",
    "        list_of_lists.append([1,1])\n",
    "        list_of_lists.append([1,1])\n",
    "        list_of_lists.append([1,1])\n",
    "        list_of_lists.append([1,1])\n",
    "        list_of_lists.append([1,1])\n",
    "        list_of_lists.append([1,1])\n",
    "        list_of_lists.append([1,1])\n",
    "        list_of_lists.append([1,1])\n",
    "        list_of_lists.append([1,1])\n",
    "        list_of_lists.append([1,1])\n",
    "        list_of_lists.append([1,1])\n",
    "        list_of_lists.append([1,3])\n",
    "        list_of_lists.append([1,2])\n",
    "        list_of_lists.append([1,2])\n",
    "        list_of_lists.append([1,2])\n",
    "        list_of_lists.append([1,2])\n",
    "        list_of_lists.append([1,2])\n",
    "        list_of_lists.append([1,2])\n",
    "        list_of_lists.append([1,2])\n",
    "        list_of_lists.append([1,2])\n",
    "        list_of_lists.append([1,2])\n",
    "        list_of_lists.append([1,2])\n",
    "        list_of_lists.append([1,2])\n",
    "        list_of_lists.append([1,2])\n",
    "        list_of_lists.append([1,2])\n",
    "        list_of_lists.append([1,2])\n",
    "        list_of_lists.append([1,2])\n",
    "        list_of_lists.append([1,2])\n",
    "        list_of_lists.append([1,2])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        test_df = pd.DataFrame(list_of_lists, columns=[\"order_no\",\"distance\"])\n",
    "        test_series = pd.Series(trip_pings_overlapping_count(test_df), name=\"distance\", index=pd.Index([1]))\n",
    "\n",
    "        list_of_values = []\n",
    "        list_of_values.append(2)\n",
    "\n",
    "        expected_series = pd.Series(\n",
    "            list_of_values,\n",
    "            name=\"distance\",\n",
    "            index=pd.Index([1])\n",
    "        )\n",
    "\n",
    "        pd.testing.assert_series_equal(expected_series, test_series)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "test_pings_overlapping_count()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "test_time_on_point_accept()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "x = pd.Series([1,1])\n",
    "y = pd.Series([1,2])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "pd.testing.assert_series_equal(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute recipe outputs from inputs\n",
    "# TODO: Replace this part by your actual code that computes the output, as a Pandas dataframe\n",
    "# NB: DSS also supports other kinds of APIs for reading and writing data. Please see doc.\n",
    "\n",
    "ghost_trip_features_df = trip_level_features # For this sample code, simply copy input to output\n",
    "\n",
    "###\n",
    "\n",
    "# Write recipe outputs\n",
    "ghost_trip_features = dataiku.Dataset(\"revelio_production_features\")\n",
    "ghost_trip_features.write_with_schema(ghost_trip_features_df)\n",
    "####"
   ]
  }
 ],
 "metadata": {
  "associatedRecipe": "compute_revelio_production_features",
  "creator": "admin",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "tags": [
   "recipe-editor"
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
